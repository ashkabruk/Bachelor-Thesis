{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5601891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "#!pip install unidecode\n",
    "#!pip install datasketch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import unidecode\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict\n",
    "from collections import Counter\n",
    "import random\n",
    "from datasketch import MinHash, MinHashLSH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40297bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_metrics(true_labels, predicted_labels):\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    for i in range(len(true_labels)):\n",
    "        golden = str(true_labels[i]).split(\", \")\n",
    "        predicted = str(predicted_labels[i]).split(\", \")\n",
    "        if len(golden) == 1 and len(predicted) == 1 and predicted == golden:\n",
    "            tn += 1\n",
    "        elif golden == predicted:\n",
    "            tp += 1\n",
    "        elif len(predicted) > len(golden):\n",
    "            fp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1score = 2*tp / (2*tp + fp + fn)\n",
    "    return accuracy, precision, recall, f1score\n",
    "\n",
    "\n",
    "\n",
    "def measure_metrics2(true_labels, predicted_labels, include_non_dups=False):\n",
    "    pre = []\n",
    "    rec = []\n",
    "    f1 = []\n",
    "\n",
    "    for i in range(len(true_labels)):\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        \n",
    "        golden = str(true_labels[i]).split(\", \")\n",
    "        predicted = str(predicted_labels[i]).split(\", \")\n",
    "        \n",
    "        # Check if there is an intersection before attempting to remove elements\n",
    "        intersection = list(set(golden).intersection(set(predicted)))\n",
    "        if intersection:\n",
    "            to_remove = intersection[0]\n",
    "            golden.remove(to_remove)\n",
    "            predicted.remove(to_remove)\n",
    "            \n",
    "        if golden or predicted:\n",
    "            for j in golden:\n",
    "                if j in predicted:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "\n",
    "            for j in predicted:\n",
    "                if j not in golden:\n",
    "                    fp += 1\n",
    "\n",
    "            if tp + fp == 0:\n",
    "                precision = 0\n",
    "            else:\n",
    "                precision = tp / (tp + fp)\n",
    "\n",
    "            if tp + fn == 0:\n",
    "                recall = 0\n",
    "            else:\n",
    "                recall = tp / (tp + fn)\n",
    "\n",
    "            if precision + recall == 0:\n",
    "                f1score = 0\n",
    "            else:\n",
    "                f1score = 2 * (precision * recall) / (precision + recall)\n",
    "                \n",
    "            pre.append(precision)\n",
    "            rec.append(recall)\n",
    "            f1.append(f1score)\n",
    "            \n",
    "        elif include_non_dups == True:\n",
    "            pre.append(1)\n",
    "            rec.append(1)\n",
    "            f1.append(1)\n",
    "\n",
    "    return np.mean(pre), np.mean(rec), np.mean(f1)\n",
    "\n",
    "\n",
    "def replace_non_letters(input_string):\n",
    "    return re.sub(r\"[^a-zA-Z\\s]\", \" \", input_string)\n",
    "\n",
    "def unidecoded(panda_column):\n",
    "    return panda_column.astype(str).apply(\n",
    "        lambda x: unidecode.unidecode(\n",
    "            x.replace(\"ä\", \"ae\").replace(\"ö\", \"oe\").replace(\"ü\", \"ue\")\n",
    "             .replace('Ä', 'Ae').replace('Ö', 'Oe').replace('Ü', 'Ue')))\n",
    "\n",
    "true = [103]\n",
    "predicted = [103]\n",
    "\n",
    "measure_metrics2(true, predicted, include_non_dups=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e378e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_emails(first_name, last_name):\n",
    "    # Diese Funktion erzeugt eine Liste von E-Mail-Adressen basierend auf Vor- und Nachnamen\n",
    "    # Diese Liste enthält verschiedene Formate wie Vorname.Nachname, VNach, Vorname usw.\n",
    "    emails = []\n",
    "    emails.append(f\"{first_name.lower()}.{last_name.lower()}\")\n",
    "    emails.append(f\"{first_name.lower()[0]}{last_name.lower()}\")\n",
    "    emails.append(f\"{first_name.lower()}\")\n",
    "    emails.append(f\"{first_name.lower()[0]}.{last_name.lower()}\")\n",
    "    emails.append(\"anderes\")\n",
    "    emails.append(\"info\")\n",
    "    emails.append(f\"{last_name.lower()}\")\n",
    "    emails.append(f\"{first_name.lower()}{last_name.lower()}\")\n",
    "    emails.append(f\"{first_name.lower()}.{last_name.lower()}1990\")  # Vor.NachnameJahr\n",
    "    return emails\n",
    "\n",
    "def fake_emails(first_name, last_name):\n",
    "    # Diese Funktion generiert eine E-Mail-Adresse basierend auf den gegebenen Wahrscheinlichkeiten\n",
    "    distr = {\n",
    "        \"vor.nach\": 55/100,\n",
    "        \"vnach\": 10/100,\n",
    "        \"vor\": 9/100,\n",
    "        \"v.nach\": 6/100,\n",
    "        \"anderes\": 6/100,\n",
    "        \"info\": 5/100,\n",
    "        \"nach\": 4/100,\n",
    "        \"vornach\": 3/100,\n",
    "        \"vor.nachjahr\": 2/100\n",
    "    }\n",
    "    \n",
    "    # Generiere eine Liste von E-Mail-Adressen\n",
    "    emails = generate_emails(first_name, last_name)\n",
    "    \n",
    "    # Wähle zufällig eine E-Mail-Adresse basierend auf den Wahrscheinlichkeiten aus\n",
    "    random_percentage = random.random()\n",
    "    total = 0\n",
    "    i = 0\n",
    "    for scenario, percentage in distr.items():\n",
    "        total += percentage\n",
    "        if random_percentage <= total:\n",
    "\n",
    "            return emails[i]  # Gib die E-Mail-Adresse zurück\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "def plausible_email(first_name, last_name, email):\n",
    "    email = email.split(\"@\")[0]\n",
    "    email = re.sub(r'\\d+', '', email)\n",
    "    plausible_formats = [\n",
    "        f\"{first_name.lower()}.{last_name.lower()}\",\n",
    "        f\"{first_name.lower()}{last_name.lower()}\",\n",
    "        f\"{first_name.lower()[0]}{last_name.lower()}\",\n",
    "        f\"{first_name.lower()}\",\n",
    "        f\"{first_name.lower()[0]}.{last_name.lower()}\",\n",
    "        f\"{last_name.lower()}\",\n",
    "    ]\n",
    "    \n",
    "    if first_name and last_name in email:\n",
    "        return True\n",
    "    else:\n",
    "        return email in plausible_formats\n",
    "\n",
    "# Beispielvor- und nachname\n",
    "first_name = \"Max\"\n",
    "last_name = \"Mustermann\"\n",
    "\n",
    "df = pd.read_excel(\"Testcases.xlsx\")\n",
    "\n",
    "for vor, nach, email in zip(unidecoded(df[\"Vorname\"]).to_list(), unidecoded(df[\"Nachname\"]).to_list(), unidecoded(df[\"Email\"]).to_list()):\n",
    "    res = plausible_email(vor, nach, email)\n",
    "    print(res)\n",
    "    # Generiere eine E-Mail-Adresse basierend auf den Wahrscheinlichkeiten\n",
    "    #generated_email = fake_emails(unidecode(str(vor)), unidecode(str(nach)))\n",
    "\n",
    "    # Ausgabe der generierten E-Mail-Adresse\n",
    "    #print(generated_email)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a537c316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Testcases.xlsx\")\n",
    "\n",
    "#replace Umlaute\n",
    "df[\"Vorname\"] = df['Vorname'].str.replace('ä', 'ae').str.replace('ö', 'oe').str.replace('ü', 'ue').str.replace('Ä', 'Ae').str.replace('Ö', 'Oe').str.replace('Ü', 'Ue')\n",
    "df[\"Nachname\"] = df['Nachname'].str.replace('ä', 'ae').str.replace('ö', 'oe').str.replace('ü', 'ue').str.replace('Ä', 'Ae').str.replace('Ö', 'Oe').str.replace('Ü', 'Ue')\n",
    "\n",
    "def simple(full_name):\n",
    "    namen = {}\n",
    "\n",
    "    for index, name in full_name.items():\n",
    "        if name == \"\":\n",
    "            continue\n",
    "\n",
    "        if name in namen:\n",
    "            namen[name].append(int(df.at[index, \"ID\"]))\n",
    "        else:\n",
    "            namen[name] = [int(df.at[index, \"ID\"])]\n",
    "\n",
    "    df[\"Simple Match\"] = str(0)\n",
    "    for n in namen:\n",
    "        for m in namen[n]:\n",
    "            df.at[m-1, \"Simple Match\"] = str(namen[n])[1:-1]\n",
    "\n",
    "\n",
    "    sorted_dict = dict(sorted(namen.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6468b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "import pandas as pd\n",
    "\n",
    "def soundex(full_name):\n",
    "    soundex_mapping = {\n",
    "        \"a\": \"0\", \"e\": \"0\", \"i\": \"0\", \"o\": \"0\", \"u\": \"0\", \"ä\": \"0\", \"ö\": \"0\", \"ü\": \"0\", \"y\": \"0\", \"j\": \"0\", \"h\": \"0\",\n",
    "        \"b\": \"1\", \"p\": \"1\", \"f\": \"1\", \"v\": \"1\", \"w\": \"1\",\n",
    "        \"c\": \"2\", \"s\": \"2\", \"k\": \"2\", \"g\": \"2\", \"q\": \"2\", \"x\": \"2\", \"z\": \"2\", \"ß\": \"2\",\n",
    "        \"d\": \"3\", \"t\": \"3\",\n",
    "        \"l\": \"4\",\n",
    "        \"m\": \"5\", \"n\": \"5\",\n",
    "        \"r\": \"6\",\n",
    "        \"ch\": \"7\", \"sch\": \"7\", \"sh\": \"7\",\n",
    "        \"-\": \" \"\n",
    "    }\n",
    "\n",
    "    soundex_codes = {}\n",
    "\n",
    "    for index, name in full_name.items():\n",
    "        if name == \"\":\n",
    "            continue\n",
    "\n",
    "        name = name.lower()\n",
    "        name = name.replace(\"sch\", \"7\").replace(\"ch\", \"7\").replace(\"sh\", \"7\")\n",
    "\n",
    "        soundex_code = name[0].upper()\n",
    "\n",
    "        previous_digit = \"\"\n",
    "        for letter in name[1:]:\n",
    "            if letter in soundex_mapping:\n",
    "                current_digit = soundex_mapping[letter]\n",
    "                if current_digit != previous_digit and current_digit != \"0\":\n",
    "                    soundex_code += current_digit\n",
    "                    previous_digit = current_digit\n",
    "\n",
    "        soundex_code = soundex_code[:4]\n",
    "\n",
    "        while len(soundex_code) < 4:\n",
    "            soundex_code += '0' \n",
    "        if soundex_code in soundex_codes:\n",
    "            soundex_codes[soundex_code].append(index+1)\n",
    "        else:\n",
    "            soundex_codes[soundex_code] = [index+1]\n",
    "            \n",
    "    df[\"Soundex\"] = str(0)\n",
    "    \n",
    "    for n in soundex_codes:\n",
    "        for m in soundex_codes[n]:\n",
    "            df.at[m-1, \"Soundex\"] = str(soundex_codes[n])[1:-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbf9c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Soundex representation\n",
    "df = pd.read_excel(\"Testcases.xlsx\")\n",
    "\n",
    "def soundex_custom(full_name):\n",
    "    soundex_mapping = {\n",
    "            \"a\": \"0\", \"e\": \"0\", \"i\": \"0\", \"o\": \"0\", \"u\": \"0\", \"ä\": \"0\", \"ö\": \"0\", \"ü\": \"0\", \"y\": \"0\", \"j\": \"0\", \"h\": \"0\",\n",
    "            \"b\": \"1\", \"p\": \"1\", \"f\": \"1\", \"v\": \"1\", \"w\": \"1\",\n",
    "            \"c\": \"2\", \"s\": \"2\", \"k\": \"2\", \"g\": \"2\", \"q\": \"2\", \"x\": \"2\", \"z\": \"2\", \"ß\": \"2\",\n",
    "            \"d\": \"3\", \"t\": \"3\",\n",
    "            \"l\": \"4\",\n",
    "            \"m\": \"5\", \"n\": \"5\",\n",
    "            \"r\": \"6\",\n",
    "            \"ch\": \"7\", \"sch\": \"7\",\n",
    "            \"-\": \" \"\n",
    "        }\n",
    "\n",
    "    soundex_namen = {}\n",
    "\n",
    "    for index, name in full_name.items():\n",
    "\n",
    "        if name == \"\" or pd.isna(name):\n",
    "            continue\n",
    "\n",
    "        name = str(name).replace(\"sch\", \"7\").replace(\"ch\", \"7\").replace(\"sh\", \"7\")\n",
    "\n",
    "        soundex_name = \"\"\n",
    "        soundex_name += name[0]\n",
    "\n",
    "        for letter in name.lower()[1:]:\n",
    "            if letter in soundex_mapping and soundex_mapping[letter] != soundex_name[-1]:\n",
    "                soundex_name += soundex_mapping[letter]\n",
    "\n",
    "            elif letter not in soundex_mapping:\n",
    "                soundex_name += letter\n",
    "                \n",
    "        if soundex_name in soundex_namen:\n",
    "            soundex_namen[soundex_name].append(int(df.at[index, \"ID\"]))\n",
    "        else:\n",
    "            soundex_namen[soundex_name] = [int(df.at[index, \"ID\"])]\n",
    "\n",
    "    df[\"Soundex Custom\"] = str(0)\n",
    "    for n in soundex_namen:\n",
    "        for m in soundex_namen[n]:\n",
    "            df.at[m-1, \"Soundex Custom\"] = str(soundex_namen[n])[1:-1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8626174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshteinDistance(A, B):\n",
    "    N, M = len(A), len(B)\n",
    "    \n",
    "    dp = [[0 for i in range(M + 1)] for j in range(N + 1)]\n",
    "\n",
    "    for j in range(M + 1):\n",
    "        dp[0][j] = j\n",
    "        \n",
    "    for i in range(N + 1):\n",
    "        dp[i][0] = i\n",
    "        \n",
    "    for i in range(1, N + 1):\n",
    "        for j in range(1, M + 1):\n",
    "            if A[i - 1] == B[j - 1]:\n",
    "                dp[i][j] = dp[i-1][j-1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(\n",
    "                    dp[i-1][j],\n",
    "                    dp[i][j-1],\n",
    "                    dp[i-1][j-1]\n",
    "                )\n",
    "\n",
    "    return dp[N][M]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93269438",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#replace Umlaute\n",
    "\n",
    "df[\"Vorname\"] = df['Vorname'].str.replace('ä', 'ae').str.replace('ö', 'oe').str.replace('ü', 'ue').str.replace('Ä', 'Ae').str.replace('Ö', 'Oe').str.replace('Ü', 'Ue')\n",
    "df[\"Nachname\"] = df['Nachname'].str.replace('ä', 'ae').str.replace('ö', 'oe').str.replace('ü', 'ue').str.replace('Ä', 'Ae').str.replace('Ö', 'Oe').str.replace('Ü', 'Ue')\n",
    "\n",
    "\n",
    "def levenshtein(full_name, max_distance=3):\n",
    "    namen = {}\n",
    "    max_distance = 3\n",
    "\n",
    "    for index, name in full_name.items():\n",
    "        if pd.isna(name):\n",
    "            continue\n",
    "        if name not in namen:\n",
    "            namen[name] = [int(df.at[index, \"ID\"])]\n",
    "        elif pd.notna(df.at[index, \"ID\"]):\n",
    "            namen[name].append(int(df.at[index, \"ID\"]))\n",
    "\n",
    "    for name in namen:\n",
    "        for n in namen:\n",
    "            if any(namen[n]) not in namen[name]:\n",
    "                if levenshteinDistance(name, n) in range(1, max_distance):\n",
    "                    namen[name] += namen[n]\n",
    "                    namen[name] = list(set(namen[name]))\n",
    "\n",
    "\n",
    "    df[\"Levenshtein\"] = str(0)\n",
    "    for n in namen:\n",
    "        for m in namen[n]:\n",
    "            df.at[m-1, \"Levenshtein\"] = str(namen[n])[1:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe540a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def koln(df, column_name):\n",
    "    koln_mapping = {\n",
    "        \"a\": \"\", \"e\": \"\", \"i\": \"\", \"o\": \"\", \"u\": \"\", \"ä\": \"\", \"ö\": \"\", \"ü\": \"\", \"y\": \"\", \"j\": \"\", \"h\": \"\",\n",
    "        \"b\": \"1\",\n",
    "        \"f\": \"3\", \"v\": \"3\", \"w\": \"3\",\n",
    "        \"g\": \"4\", \"k\": \"4\", \"q\": \"4\",\n",
    "        \"l\": \"5\",\n",
    "        \"m\": \"6\", \"n\": \"6\",\n",
    "        \"r\": \"7\",\n",
    "        \"s\": \"8\", \"z\": \"8\",\n",
    "        \"-\": \"\"\n",
    "    }\n",
    "\n",
    "    def koln_encode(name):\n",
    "        if name != \"\":\n",
    "\n",
    "            koln_name = [str(name)[0]]\n",
    "\n",
    "            for n, letter in enumerate(str(name)[1:], start=1):\n",
    "                if letter == \"p\":\n",
    "                    if n < len(name) and name[n] == \"h\":\n",
    "                        koln_name.append(\"3\")\n",
    "                    else:\n",
    "                        koln_name.append(\"1\")\n",
    "\n",
    "                elif letter in \"dt\":\n",
    "                    if n < len(name) and name[n] in \"csz\":\n",
    "                        koln_name.append(\"8\")\n",
    "                    else:\n",
    "                        koln_name.append(\"2\")\n",
    "\n",
    "                elif letter == \"c\":\n",
    "                    if n == 1 and n < len(name) and name[n] in \"ahkloqrux\":\n",
    "                        koln_name.append(\"4\")\n",
    "                    elif n < len(name) and name[n] in \"ahkloqrux\" and name[n - 1] not in \"sz\":\n",
    "                        koln_name.append(\"4\")\n",
    "                    else:\n",
    "                        koln_name.append(\"8\")\n",
    "\n",
    "                elif letter == \"x\":\n",
    "                    if name[n - 1] in \"ckq\":\n",
    "                        koln_name.append(\"8\")\n",
    "                    else:\n",
    "                        koln_name.append(\"48\")\n",
    "\n",
    "                elif letter in koln_mapping and (not koln_name or koln_mapping[letter] != koln_name[-1]):\n",
    "                    koln_name.append(koln_mapping[letter])\n",
    "\n",
    "            koln_name = ''.join(koln_name[i] for i in range(len(koln_name)) if i == 0 or koln_name[i] != koln_name[i-1])\n",
    "            return koln_name\n",
    "        \n",
    "\n",
    "    df[\"Koln\"] = df[column_name].apply(koln_encode)\n",
    "\n",
    "    koln_namen = df.groupby(\"Koln\")[\"ID\"].apply(list).to_dict()\n",
    "\n",
    "    df[\"Koln\"] = df[\"Koln\"].map(lambda k: \", \".join(map(str, koln_namen.get(k, []))) or \"0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a970ada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(text, n=2):\n",
    "    text = f\"{'#' * (n-1)}{text.lower().replace(' ', '_')}{'#' * (n-1)}\"\n",
    "    return [text[i:i+n] for i in range(len(text) - n + 1)]\n",
    "\n",
    "def cosine_similarity(ngrams1, ngrams2):\n",
    "    freq_vector1 = Counter(ngrams1)\n",
    "    freq_vector2 = Counter(ngrams2)\n",
    "\n",
    "    unique_ngrams = set(freq_vector1.keys()) | set(freq_vector2.keys())\n",
    "\n",
    "    dot_product = sum(freq_vector1[ngram] * freq_vector2[ngram] for ngram in unique_ngrams)\n",
    "\n",
    "    magnitude1 = np.sqrt(sum(freq_vector1[ngram] ** 2 for ngram in unique_ngrams))\n",
    "    magnitude2 = np.sqrt(sum(freq_vector2[ngram] ** 2 for ngram in unique_ngrams))\n",
    "\n",
    "    similarity = dot_product / (magnitude1 * magnitude2)\n",
    "\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def ngram_similarity(full_name, ngram=3, border=0.65):\n",
    "    df[\"Ngram Similarity\"] = str(0)\n",
    "    similarities = {}\n",
    "    names = full_name.to_list()\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        for j in range(i + 1, len(names)):\n",
    "            ngrams1 = ngrams(names[i], ngram)\n",
    "            ngrams2 = ngrams(names[j], ngram)\n",
    "            if cosine_similarity(ngrams1, ngrams2) > border:\n",
    "                if i not in similarities:\n",
    "                    similarities[i] = [i+1, j+1]\n",
    "                else:\n",
    "                    similarities[i].append(j+1)\n",
    "                \n",
    "                print(cosine_similarity(ngrams1, ngrams2), names[i], names[j])\n",
    "\n",
    "        if i not in similarities:\n",
    "            similarities[i] = [i+1]\n",
    "\n",
    "    for i in similarities:\n",
    "        for j in similarities[i]:\n",
    "            if df.at[j-1, \"Ngram Similarity\"] == str(0):\n",
    "                df.at[j-1, \"Ngram Similarity\"] = str(similarities[i])[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ea1cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minhash_for_ngrams(ngrams, num_perm=128):\n",
    "    mhash = MinHash(num_perm=num_perm)\n",
    "    for ngram in ngrams:\n",
    "        mhash.update(ngram.encode(\"utf-8\"))\n",
    "    return mhash\n",
    "\n",
    "def lsh_similarity_check(full_name, ngram_size=2, threshold=0.65, num_perm=128):\n",
    "    lsh = MinHashLSH(threshold=threshold, num_perm=num_perm)\n",
    "    minhashes = {}\n",
    "    similarities = []\n",
    "\n",
    "    for index, name in full_name.items():\n",
    "        if name == \"\":\n",
    "            continue\n",
    "        name_ngrams = ngrams(str(name), ngram_size)\n",
    "        mhash = minhash_for_ngrams(name_ngrams, num_perm)\n",
    "        lsh.insert(f\"name{index}\", mhash)\n",
    "        minhashes[f\"name{index}\"] = mhash\n",
    "\n",
    "    df[\"LSH Similarity\"] = pd.Series([set() for _ in range(len(df))])\n",
    "\n",
    "    for key, minhash in minhashes.items():\n",
    "        potential_matches = lsh.query(minhash)\n",
    "        index_key = int(key.replace(\"name\", \"\"))\n",
    "        for match in potential_matches:\n",
    "            if key != match:\n",
    "                index_match = int(match.replace(\"name\", \"\"))\n",
    "                actual_similarity = minhash.jaccard(minhashes[match])\n",
    "                if actual_similarity >= threshold:\n",
    "                    similarities.append(actual_similarity)\n",
    "                    df.at[index_key, \"LSH Similarity\"].add(index_match+1)\n",
    "                    df.at[index_match, \"LSH Similarity\"].add(index_key+1)\n",
    "            elif key == match:\n",
    "                df.at[index_key, \"LSH Similarity\"].add(index_key+1)\n",
    "                \n",
    "                \n",
    "    df[\"LSH Similarity\"] = df[\"LSH Similarity\"].apply(lambda x: str(sorted(list(x)))[1:-1] or \"0\")\n",
    "\n",
    "\n",
    "def jaccard_similarity(list1, list2):\n",
    "    set1 = set(list1)\n",
    "    set2 = set(list2)\n",
    "    \n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    \n",
    "    if len(union) == 0:\n",
    "        return 1.0\n",
    "    jaccard_index = len(intersection) / len(union)\n",
    "    \n",
    "    return jaccard_index\n",
    "\n",
    "print(jaccard_similarity(\"Henri Waternoose\", \"Henry Peter Waternose\"))\n",
    "print(cosine_similarity(ngrams(\"johann johann\", 3), ngrams(\"johann seeler\", 3)))\n",
    "\n",
    "\n",
    "print(jaccard_similarity(ngrams(\"robert frei\", 2), ngrams(\"robert frei robert\", 2)))\n",
    "print(jaccard_similarity(ngrams(\"Henri Waternoose\", 2), ngrams(\"Henry Peter Waternose\", 2)))\n",
    "print(cosine_similarity(ngrams(\"Henri Waternoose\", 3), ngrams(\"Henry Peter Waternose\", 3)))\n",
    "\n",
    "print(jaccard_similarity(ngrams(\"mario mueller\", 3), ngrams(\"maria mueller\", 3)))\n",
    "print(jaccard_similarity(ngrams(\"juergen kaiser\", 3), ngrams(\"juergen geiser\", 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090d9236",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rerun all algorithms, if \"TypeError: 'tuple' object is not callable\" appears\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_excel(\"Testcases.xlsx\")\n",
    "import time\n",
    "\n",
    "vornamen = unidecoded(df[\"Vorname\"]).to_list()\n",
    "nachnamen = unidecoded(df[\"Nachname\"]).to_list()\n",
    "emails = unidecoded(df[\"Email\"]).to_list()\n",
    "\n",
    "\n",
    "df[\"Standardized\"] = str(0)\n",
    "index = 0\n",
    "for vor, nach, email in zip(vornamen, nachnamen, emails):\n",
    "    full_name = replace_non_letters(f\"{vor} {nach}\".lower())\n",
    "    email_prefix = email.split(\"@\")[0].lower()\n",
    "    email_prefix = replace_non_letters(re.sub(r'\\d+', '', email_prefix))\n",
    "    \n",
    "    if vor == \"nan\" or nach == \"nan\":\n",
    "        if email != \"nan\":\n",
    "            to_check = email.split(\".\")[0]\n",
    "                                                               \n",
    "        else:\n",
    "            to_check = \"\"\n",
    "            \n",
    "    elif plausible_email(vor, nach, email):\n",
    "        to_check = full_name\n",
    "    \n",
    "    elif cosine_similarity(ngrams(full_name, 2), ngrams(email_prefix, 2)) > 0.65:\n",
    "        to_check = email_prefix\n",
    "        print(to_check, \"|\", full_name)\n",
    "    \n",
    "    else:\n",
    "        to_check = full_name\n",
    "    df.at[index, \"Standardized\"] = to_check\n",
    "    index += 1\n",
    "    \n",
    "simple(df[\"Standardized\"])\n",
    "soundex(df[\"Standardized\"])\n",
    "soundex_custom(df[\"Standardized\"])\n",
    "koln(df, \"Standardized\")\n",
    "levenshtein(df[\"Standardized\"])\n",
    "ngram_similarity(df[\"Standardized\"], 3)\n",
    "start = time.time()\n",
    "lsh_similarity_check(df[\"Standardized\"], 2)\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "df.to_excel(\"output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a255e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"output.xlsx\")\n",
    "\n",
    "simple = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Simple Match\"].to_list())\n",
    "soundex = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Soundex\"].to_list())\n",
    "soundex_custom = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Soundex Custom\"].to_list())\n",
    "koln = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Koln\"].to_list())\n",
    "ls = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Levenshtein\"].to_list())\n",
    "cos = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Ngram Similarity\"].to_list())\n",
    "lsh = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"LSH Similarity\"].to_list())\n",
    "\n",
    "simple, soundex, soundex_custom, koln, ls, cos, lsh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac852825",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rerun all algorithms, if \"TypeError: 'tuple' object is not callable\" appears\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"restaurants.tsv\", sep=\"\\t\")\n",
    "import time\n",
    "print(df)\n",
    "namen = unidecoded(df[\"name\"]).to_list()\n",
    "\n",
    "df[\"Standardized\"] = str(0)\n",
    "index = 0\n",
    "for name in namen:\n",
    "    df.at[index, \"Standardized\"] = replace_non_letters(name)\n",
    "\n",
    "    index += 1\n",
    "    \n",
    "simple(df[\"Standardized\"])\n",
    "soundex(df[\"Standardized\"])\n",
    "soundex_custom(df[\"Standardized\"])\n",
    "koln(df, \"Standardized\")\n",
    "levenshtein(df[\"Standardized\"])\n",
    "ngram_similarity(df[\"Standardized\"])\n",
    "start = time.time()\n",
    "lsh_similarity_check(df[\"Standardized\"])\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "df.to_excel(\"output - restaurant.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63683c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"output - restaurant.xlsx\")\n",
    "\n",
    "simple = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Simple Match\"].to_list(), include_non_dups=True)\n",
    "soundex = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Soundex\"].to_list(), include_non_dups=True)\n",
    "soundex_custom = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Soundex Custom\"].to_list(), include_non_dups=True)\n",
    "koln = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Koln\"].to_list(), include_non_dups=True)\n",
    "ls = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Levenshtein\"].to_list(), include_non_dups=True)\n",
    "cos = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Ngram Similarity\"].to_list(), include_non_dups=True)\n",
    "ngram = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"LSH Similarity\"].to_list(), include_non_dups=True)\n",
    "\n",
    "simple, soundex, soundex_custom, koln, ls, cos, ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb51c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rerun all algorithms, if \"TypeError: 'tuple' object is not callable\" appears\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv(\"cora.tsv\", sep=\"\\t\")\n",
    "import time\n",
    "\n",
    "authors = unidecoded(df[\"authors\"]).to_list()\n",
    "title = unidecoded(df[\"authors\"]).to_list()\n",
    "\n",
    "df[\"Standardized\"] = str(0)\n",
    "index = 0\n",
    "for author, tit in zip(authors, title):\n",
    "    \n",
    "    if author == \"nan\":\n",
    "        to_check = tit\n",
    "    \n",
    "    else:\n",
    "        to_check = author\n",
    "    df.at[index, \"Standardized\"] = to_check\n",
    "    index += 1\n",
    "    \n",
    "simple(df[\"Standardized\"])\n",
    "soundex(df[\"Standardized\"])\n",
    "soundex_custom(df[\"Standardized\"])\n",
    "koln(df, \"Standardized\")\n",
    "levenshtein(df[\"Standardized\"])\n",
    "ngram_similarity(df[\"Standardized\"])\n",
    "start = time.time()\n",
    "lsh_similarity_check(df[\"Standardized\"])\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "df.to_excel(\"output - cora.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"output - cora.xlsx\")\n",
    "\n",
    "simple = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Simple Match\"].to_list())\n",
    "soundex = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Soundex\"].to_list())\n",
    "soundex_custom = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Soundex Custom\"].to_list())\n",
    "koln = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Koln\"].to_list())\n",
    "ls = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Levenshtein\"].to_list())\n",
    "cos = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"Ngram Similarity\"].to_list())\n",
    "ngram = measure_metrics2(df[\"Duplikat mit Id\"].to_list(), df[\"LSH Similarity\"].to_list())\n",
    "\n",
    "simple, soundex, soundex_custom, koln, ls, cos, ngram"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
